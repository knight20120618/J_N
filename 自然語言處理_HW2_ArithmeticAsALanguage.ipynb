{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM-arithmetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn\n",
    "import torch.nn.utils.rnn\n",
    "import torch.utils.data\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import opencc\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_path = './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(os.path.join(data_path, 'arithmetic_train.csv'))\n",
    "df_eval = pd.read_csv(os.path.join(data_path, 'arithmetic_eval.csv'))\n",
    "\n",
    "print(df_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 輸入的資料型態轉換成 str\n",
    "df_train['tgt'] = df_train['tgt'].apply(lambda x: str(x))\n",
    "df_train['src'] = df_train['src'].add(df_train['tgt'])\n",
    "df_train['len'] = df_train['src'].apply(lambda x: len(x))\n",
    "\n",
    "df_eval['tgt'] = df_eval['tgt'].apply(lambda x: str(x))\n",
    "df_eval['src'] = df_eval['src'].add(df_eval['tgt'])\n",
    "df_eval['len'] = df_eval['src'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build Dictionary\n",
    "\n",
    "    The model cannot perform calculations directly with plain text.\n",
    "    Convert all text (numbers/symbols) into numerical representations.\n",
    "    Special tokens\n",
    "        '<pad>'\n",
    "            Each sentence within a batch may have different lengths.\n",
    "            The length is padded with '<pad>' to match the longest sentence in the batch.\n",
    "        '<eos>'\n",
    "            Specifies the end of the generated sequence.\n",
    "            Without '<eos>', the model will not know when to stop generating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立字典\n",
    "char_to_id = {\n",
    "    \"<pad>\": 0,\n",
    "    \"<eos>\": 1\n",
    "}\n",
    "id_to_char = {\n",
    "    0: \"<pad>\",\n",
    "    1: \"<eos>\"\n",
    "}\n",
    "\n",
    "chars = list(\"0123456789+-*()=\")\n",
    "\n",
    "char_to_id.update({char: idx +2 for idx, char in enumerate(chars)})\n",
    "id_to_char.update({idx +2: char for idx, char in enumerate(chars)})\n",
    "\n",
    "vocab_size = len(char_to_id)\n",
    "print('Vocab size: {}'.format(vocab_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preprocessing\n",
    "\n",
    "    The data is processed into the format required for the model's input and output.\n",
    "    Example: 1+2-3=0\n",
    "        Model input: 1 + 2 - 3 = 0\n",
    "        Model output: / / / / / 0 <eos> (the '/' can be replaced with <pad>)\n",
    "        The key for the model's output is that the model does not need to predict the next character of the previous part. What matters is that once the model sees '=', it should start generating the answer, which is '0'. After generating the answer, it should also generate<eos>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 資料預處理\n",
    "def process_row(src, tgt):\n",
    "    char_id_list = [char_to_id[char] for char in src if char in char_to_id] + [char_to_id['<eos>']]\n",
    "    \n",
    "    answer_id = char_to_id[tgt] if tgt in char_to_id else 17\n",
    "    label_id_list = [0] * (len(src) - 1) + [answer_id, char_to_id['<eos>']]\n",
    "\n",
    "    return char_id_list, label_id_list\n",
    "# 資料轉換成 TOKEN\n",
    "df_train['char_id_list'], df_train['label_id_list'] = zip(*df_train.apply(lambda row: process_row(row['src'], row['tgt']), axis=1))\n",
    "df_eval['char_id_list'], df_eval['label_id_list'] = zip(*df_eval.apply(lambda row: process_row(row['src'], row['tgt']), axis=1))\n",
    "# 顯示 char_id_list 和 label_id_list ， .to_string() 使 df 資料不斷行\n",
    "print(df_eval.head().to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 參數設定\n",
    "batch_size = 64\n",
    "epochs = 2\n",
    "embed_dim = 256\n",
    "hidden_dim = 256\n",
    "lr = 0.001\n",
    "grad_clip = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Batching\n",
    "\n",
    "    Use torch.utils.data.Dataset to create a data generation tool called dataset.\n",
    "    The, use torch.utils.data.DataLoader to randomly sample from the dataset and group the samples into batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, sequences): # 資料初始化\n",
    "        self.sequences = sequences\n",
    "    \n",
    "    def __len__(self): # 資料長度回傳\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, index): # 資料擷取\n",
    "        x = self.sequences.iloc[index, 0][:-1] # 輸入元素移除最後一個\n",
    "        y = self.sequences.iloc[index, 1][1:] # 輸出元素向右移動一個\n",
    "        return x, y\n",
    "\n",
    "def collate_fn(batch): # dataloader 函數\n",
    "    batch_x = [torch.tensor(data[0]) for data in batch]\n",
    "    batch_y = [torch.tensor(data[1]) for data in batch]\n",
    "    batch_x_lens = torch.LongTensor([len(x) for x in batch_x])\n",
    "    batch_y_lens = torch.LongTensor([len(y) for y in batch_y])\n",
    "    \n",
    "    # 將資料長度調整成一致\n",
    "    pad_batch_x = torch.nn.utils.rnn.pad_sequence(batch_x, batch_first=True,\n",
    "                                                  padding_value=char_to_id['<pad>'])\n",
    "    pad_batch_y = torch.nn.utils.rnn.pad_sequence(batch_y, batch_first=True,\n",
    "                                                  padding_value=char_to_id['<pad>'])\n",
    "    \n",
    "    return pad_batch_x, pad_batch_y, batch_x_lens, batch_y_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義資料集\n",
    "ds_train = Dataset(df_train[['char_id_list', 'label_id_list']])\n",
    "ds_eval = Dataset(df_eval[['char_id_list', 'label_id_list']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 載入資料集\n",
    "from torch.utils.data import DataLoader\n",
    "# shuffle 為是否打亂順序\n",
    "dl_train = DataLoader(ds_train, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "dl_eval = DataLoader(ds_eval, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Design\n",
    "\n",
    "    Execution Flow\n",
    "        Convert all characters in the sentence into embeddings.\n",
    "        Pass the embeddings through an LSTM sequentially.\n",
    "        The output of the LSTM is passed into another LSTM, and additional layers can be added.\n",
    "        The output from all time steps of the final LSTM is passed through a Fully Connected layer.\n",
    "        The character corresponding to the maximum value across all output dimensions is selected as the next character.\n",
    "    Loss Function\n",
    "        Since this is a classification task, Cross Entropy is used as the loss function.\n",
    "    Gradient Update\n",
    "        Adam algorithm is used for gradient updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPU or GPU\n",
    "dml = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharRNN(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim):\n",
    "        super(CharRNN, self).__init__()\n",
    "        \n",
    "        self.embedding = torch.nn.Embedding(num_embeddings=vocab_size, embedding_dim=embed_dim,\n",
    "                                            padding_idx=char_to_id['<pad>'])\n",
    "        \n",
    "        self.rnn_layer1 = torch.nn.LSTM(input_size=embed_dim, hidden_size=hidden_dim,\n",
    "                                        batch_first=True)\n",
    "        \n",
    "        self.rnn_layer2 = torch.nn.LSTM(input_size=hidden_dim, hidden_size=hidden_dim,\n",
    "                                        batch_first=True)\n",
    "        \n",
    "        self.linear = torch.nn.Sequential(torch.nn.Linear(in_features=hidden_dim, out_features=hidden_dim),\n",
    "                                          torch.nn.ReLU(),\n",
    "                                          torch.nn.Linear(in_features=hidden_dim, out_features=vocab_size))\n",
    "\n",
    "    def forward(self, batch_x, batch_x_lens):\n",
    "        return self.encoder(batch_x, batch_x_lens)\n",
    "\n",
    "    def encoder(self, batch_x, batch_x_lens): # 前向傳導模型\n",
    "        batch_x = self.embedding(batch_x)\n",
    "        \n",
    "        batch_x = torch.nn.utils.rnn.pack_padded_sequence(batch_x, batch_x_lens,\n",
    "                                                            batch_first=True, enforce_sorted=False)\n",
    "        \n",
    "        batch_x, _ = self.rnn_layer1(batch_x)\n",
    "        batch_x, _ = self.rnn_layer2(batch_x)\n",
    "        \n",
    "        batch_x, _ = torch.nn.utils.rnn.pad_packed_sequence(batch_x, batch_first=True)\n",
    "        \n",
    "        batch_x = self.linear(batch_x)\n",
    "        \n",
    "        return batch_x\n",
    "\n",
    "    def generator(self, start_char, max_len=200):\n",
    "        char_list = [char_to_id[c] for c in start_char]\n",
    "        \n",
    "        next_char = None\n",
    "        \n",
    "        while len(char_list) < max_len:\n",
    "            input_tensor = torch.tensor([[char_list[-1]]]).to(dml)\n",
    "\n",
    "            embedded = self.embedding(input_tensor)\n",
    "            output, _ = self.rnn_layer1(embedded)\n",
    "            output, _ = self.rnn_layer2(output)\n",
    "            # 線性預測\n",
    "            last_output = output[:, -1, :]\n",
    "            y = self.linear(last_output)\n",
    "            # 預測下個字元\n",
    "            next_char = torch.argmax(y, dim=1).item()\n",
    "            \n",
    "            if next_char == char_to_id['<eos>']:\n",
    "                break\n",
    "\n",
    "            char_list.append(next_char)\n",
    "            \n",
    "        return [id_to_char[ch_id] for ch_id in char_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(2) # 設定隨機種子\n",
    "model = CharRNN(vocab_size, embed_dim, hidden_dim).to(dml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 設定損失函數\n",
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=0)\n",
    "# 設定優化器\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training\n",
    "\n",
    "    The outer for loop controls the epoch\n",
    "        The inner for loop uses data_loader to retrieve batches.\n",
    "            Pass the batch to the model for training.\n",
    "            Compare the predicted results batch_pred_y with the true labels batch_y using Cross Entropy to calculate the loss loss\n",
    "            Use loss.backward to automatically compute the gradients.\n",
    "            Use torch.nn.utils.clip_grad_value_ to limit the gradient values between -grad_clip < and < grad_clip.\n",
    "            Use optimizer.step() to update the model (backpropagation).\n",
    "    After every 1000 batches, output the current loss to monitor whether it is converging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "\n",
    "model.train()\n",
    "\n",
    "i = 0 # 初始化\n",
    "for epoch in range(1, epochs + 1):\n",
    "    # 進度條\n",
    "    bar = tqdm(dl_train, desc=f\"Train epoch {epoch}\")\n",
    "    \n",
    "    for batch_x, batch_y, batch_x_lens, batch_y_lens in bar:\n",
    "        batch_x = batch_x.to(dml)\n",
    "        batch_y = batch_y.to(dml)\n",
    "\n",
    "        # 清除梯度\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 前向傳導\n",
    "        batch_pred_y = model(batch_x, batch_x_lens)\n",
    "        \n",
    "        # 計算損失\n",
    "        loss = criterion(batch_pred_y.view(-1, batch_pred_y.size(-1)), batch_y.view(-1))\n",
    "        \n",
    "        # 後向傳導\n",
    "        loss.backward()\n",
    "\n",
    "        # 防止梯度爆炸\n",
    "        torch.nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n",
    "        \n",
    "        # 在模型使用優化器\n",
    "        optimizer.step()\n",
    "        \n",
    "        i += 1\n",
    "        if i % 50 == 0:\n",
    "            bar.set_postfix(loss=loss.item())\n",
    "    \n",
    "    # 模型評估\n",
    "    bar = tqdm(dl_eval, desc=f\"Validation epoch {epoch}\")\n",
    "    matched = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch_x, batch_y, batch_x_lens, batch_y_lens in bar:\n",
    "        batch_x = batch_x.to(dml)\n",
    "        batch_y = batch_y.to(dml)\n",
    "\n",
    "        predictions = model(batch_x, batch_x_lens)\n",
    "        _, predicted_indices = torch.max(predictions, dim=-1)\n",
    "        \n",
    "        matched += (predicted_indices.view(-1) == batch_y.view(-1)).sum().item()\n",
    "        total += batch_y.size(0)\n",
    "    \n",
    "    print(matched / total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generation\n",
    "\n",
    "    Use model.generator and provide an initial character to automatically generate a sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\".join(model.generator('1+1='))) # 模型測試"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
